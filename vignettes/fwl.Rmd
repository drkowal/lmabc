---
title: "STAT 413 Final Project"
author: "Caleb Fikes and Prayag Gordy"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{STAT 413 Final Project}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
# When you start, run devtools::load_all() in the console
# When you want to knit the vignette, run devtools::build_rmd("vignettes/fwl.Rmd") in the console

library(lmabc)

set.seed(8675309)
```

```{r helpers}
one_hot <- function(K) {
  model.matrix(~ 0 + K)
}
```

## Introduction
The Frisch–Waugh–Lovell theorem is a result concerning regression. First found in a 1907 paper by George Udny Yule, the theorem is commonly named after three econometricians who re-proved components of it in 1933, 1963, and 2008. The goal of the FWL theorem is to "partial out" some of the predictors while maintaining the same coefficient estimates on the others.

### Theorem statement
Consider a regression $y \sim X_1 + X_2$, where $y \in \mathbb{R}^{n}$, $X_1 \in \mathbb{R}^{n \times p_1}$, and $X_2 \in \mathbb{R}^{n \times p_2}$.

The FWL theorem states that $\hat{\beta_2}$, the coefficient estimates for the columns of $X_2$, is equivalent to $\tilde{\beta}$, the coefficient estimates of the regression $\tilde{y} \sim \tilde{X_2}$, where $\tilde{y}$ is the residual vector of the regression $y \sim X_1$ and $\tilde{X_2}$ is the residual vector of $X_2 \sim X_1$. Equivalently, one could write $e^{y \sim X_1} \sim e^{X_2 \sim X_1}$.

The strong FWL theorem further states that the variances of coefficients $\hat{\beta}_2$ and $\tilde{\beta}$ are identical up to a correction for degrees of freedom.

We will prove both parts of the theorem in this tutorial.

### Problem statement
The FWL theorem does not always work. Consider the regression $y \sim X + K + X:K$, where $X \in \mathbb{R}^{n \times p}$, $K$ is a categorical predictor, and $X:K$ is their interaction. Because standard linear regression sets a "baseline" category, one cannot partial out the interaction columns. We will introduce linear regression with abundance-based constraints, an alternative characterization of OLS linear regression that will step in for the FWL in this situation.

## A gentle beginning
### Real-world example
We will use the Penn Birthweight dataset to show the power of the FWL.

```{r}
df <- haven::read_dta("/Users/Prayag/Documents/Rice/ECON 320/320 homework/data/pennbirthwgt1-1.dta")
```





