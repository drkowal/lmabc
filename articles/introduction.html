<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>The 'ABCs' of `lmabc`: linear regression with categorical covariates • lmabc</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="The 'ABCs' of `lmabc`: linear regression with categorical covariates">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">lmabc</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/introduction.html">The 'ABCs' of `lmabc`: linear regression with categorical covariates</a></li>
    <li><a class="dropdown-item" href="../articles/limitations.html">Limitations of lmabc</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/drkowal/lmabc/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>The 'ABCs' of `lmabc`: linear regression with categorical covariates</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/drkowal/lmabc/blob/main/vignettes/introduction.Rmd" class="external-link"><code>vignettes/introduction.Rmd</code></a></small>
      <div class="d-none name"><code>introduction.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="overview">Overview<a class="anchor" aria-label="anchor" href="#overview"></a>
</h2>
<p>Regression analysis commonly features categorical (or nominal)
covariates, such as race, sex, group/experimental assignments, and many
other examples. These variables may appear alongside other covariates,
as in the <em>main-only</em> (or ANCOVA) model</p>
<p><code>y ~ x + race</code></p>
<p>or interacted with other variables, as in the <em>group-modified</em>
model</p>
<p><code>y ~ x + race + x:race</code></p>
<p>(here we use <code>race</code> as our default categorical variable
for clarity).</p>
<p>The group-modified model estimates group-specific effects of
<code>x</code> on the response <code>y</code> (e.g., does exposure to a
pollutant <code>x</code> more adversely impact the health <code>y</code>
of certain subpopulations?). Specifically, the linear model expresses
the expectation of the response variable <code>y</code> at given
<code>x</code> and <code>race</code> values:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Y</mi><mo stretchy="false" form="prefix">|</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo>,</mo><mi>r</mi><mi>a</mi><mi>c</mi><mi>e</mi><mo>=</mo><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>α</mi><mn>0</mn></msub><mo>+</mo><msub><mi>α</mi><mn>1</mn></msub><mi>x</mi><mo>+</mo><msub><mi>β</mi><mi>r</mi></msub><mo>+</mo><msub><mi>γ</mi><mi>r</mi></msub><mi>x</mi></mrow><annotation encoding="application/x-tex">
E(Y | X = x, race = r) =  \mu(x, r) = \alpha_0 + \alpha_1 x + \beta_r + \gamma_r x
</annotation></semantics></math> (here <code>x</code> is continuous). As
a result, we obtain <em>group-specific intercepts</em>,
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>α</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">
\mu(0, r) = \alpha_0 + \beta_r
</annotation></semantics></math> and <em>group-specific slopes</em>,
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>,</mo><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>α</mi><mn>1</mn></msub><mo>+</mo><msub><mi>γ</mi><mi>r</mi></msub><mi>.</mi></mrow><annotation encoding="application/x-tex">
\mu(x+1, r) - \mu(x,r) = \alpha_1 + \gamma_r.
</annotation></semantics></math> The main-only model is recovered when
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>γ</mi><mi>r</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\gamma_r = 0</annotation></semantics></math>
for all <code>race</code> groups
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>r</mi><annotation encoding="application/x-tex">r</annotation></semantics></math>.
Then the slope is global and does not depend on <code>race</code>:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>,</mo><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>α</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mu(x+1, r) - \mu(x,r) = \alpha_1</annotation></semantics></math>.</p>
<p>However, both the main-only and the group-modified models have too
many parameters. This is known as the “dummy variable trap”: to
numerically encode
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi><annotation encoding="application/x-tex">L</annotation></semantics></math>
levels of a categorical variable, only
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">L-1</annotation></semantics></math>
dummy variables are needed. Here, both models have group-specific
intercepts, yet these are parametrized by group-specific coefficients
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>β</mi><mi>r</mi></msub><annotation encoding="application/x-tex">\beta_r</annotation></semantics></math><em>and</em> a global coefficient
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>α</mi><mn>0</mn></msub><annotation encoding="application/x-tex">\alpha_0</annotation></semantics></math>.
Clearly, this uses one more parameter than necessary. A similar problem
occurs for group-specific slopes. Without modification, these parameters
are not estimable or interpretable.</p>
<p>The central question is then, how best to parametrize (or constrain)
these group-specific intercepts and slopes? The choice has significant
implications for <strong>statistical efficiency</strong>,
<strong>equitability</strong>, and
<strong>interpretability</strong>.</p>
</div>
<div class="section level2">
<h2 id="example-dataset">Example Dataset<a class="anchor" aria-label="anchor" href="#example-dataset"></a>
</h2>
<p>We generate a simulated dataset with a continuous response variable
<code>y</code>, a continuous covariate <code>x</code>, and two
categorical variables, <code>race</code> and <code>sex</code>.</p>
<p>To mimic the challenges of real data analysis, the simulated
covariates are <em>dependent</em>: <code>x</code> depends on
<code>race</code>, both in mean and distribution,</p>
<p><img src="introduction_files/figure-html/unnamed-chunk-3-1.png" width="700" style="display: block; margin: auto;"></p>
<p>while <code>race</code> and <code>sex</code> are highly dependent
categorical variables:</p>
<table class="table">
<caption>Simulated data proportions: sex (rows) and race
(columns)</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">A</th>
<th align="right">B</th>
<th align="right">C</th>
<th align="right">D</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">uu</td>
<td align="right">0.292</td>
<td align="right">0.126</td>
<td align="right">0.058</td>
<td align="right">0.078</td>
</tr>
<tr class="even">
<td align="left">vv</td>
<td align="right">0.056</td>
<td align="right">0.028</td>
<td align="right">0.104</td>
<td align="right">0.258</td>
</tr>
</tbody>
</table>
<p>We will consider estimation and inference with various combinations
of the predictors <code>x</code>, <code>race</code>, and
<code>sex</code> (and their interactions). The <code>race</code> and
<code>sex</code> variables use arbitrary labeling to avoid any
misleading race- or sex-specific effects in our example regression
output.</p>
</div>
<div class="section level2">
<h2 id="default-strategies-the-problem">Default strategies: the problem<a class="anchor" aria-label="anchor" href="#default-strategies-the-problem"></a>
</h2>
<p>Suppose we call <code>lm</code> to fit the group-modified model:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_lm</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span> <span class="op">+</span> <span class="va">race</span> <span class="op">+</span> <span class="va">x</span><span class="op">:</span><span class="va">race</span><span class="op">)</span></span></code></pre></div>
<p>The <code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code> output appears as follows:</p>
<table class="table">
<caption>Default output: lm(y ~ x + race + x:race)</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">Estimate</th>
<th align="right">Std. Error</th>
<th align="right">t value</th>
<th align="right">Pr(&gt;|t|)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">1.95</td>
<td align="right">0.35</td>
<td align="right">5.62</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">x</td>
<td align="right">1.51</td>
<td align="right">0.07</td>
<td align="right">22.40</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">raceB</td>
<td align="right">-1.27</td>
<td align="right">0.41</td>
<td align="right">-3.14</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">raceC</td>
<td align="right">-2.36</td>
<td align="right">0.60</td>
<td align="right">-3.94</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">raceD</td>
<td align="right">-0.96</td>
<td align="right">0.36</td>
<td align="right">-2.64</td>
<td align="right">0.01</td>
</tr>
<tr class="even">
<td align="left">x:raceB</td>
<td align="right">-0.86</td>
<td align="right">0.12</td>
<td align="right">-7.17</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">x:raceC</td>
<td align="right">-0.59</td>
<td align="right">0.12</td>
<td align="right">-4.93</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">x:raceD</td>
<td align="right">-0.56</td>
<td align="right">0.09</td>
<td align="right">-6.02</td>
<td align="right">0.00</td>
</tr>
</tbody>
</table>
<p>Immediately, we notice the absence of <code>raceA</code> and
<code>x:raceA</code>. This occurs by design: <code>lm</code> uses
<em>reference group encoding</em> (RGE), which parametrizes the model by
deleting a reference group, here
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>A</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\beta_A = 0</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>γ</mi><mi>A</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\gamma_A = 0</annotation></semantics></math>.
There are several limitations of this approach.</p>
<p>First, the <code>x</code> effect is <em>misleading</em>: because
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>γ</mi><mi>A</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\gamma_A = 0</annotation></semantics></math>,
the “global” slope parameter is
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mn>1</mn></msub><mo>=</mo><msub><mi>α</mi><mn>1</mn></msub><mo>+</mo><msub><mi>γ</mi><mi>A</mi></msub><mo>=</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>,</mo><mi>A</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>A</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">
\alpha_1 = \alpha_1 + \gamma_A = \mu(x+1, A) - \mu(x,A),
</annotation></semantics></math> i.e., the group-specific <code>x</code>
effect <em>for the reference group</em> (<code>race = A</code>).
However, this is not clear from the model output, which instead appears
to present a “global” <code>x</code> effect. This presentation invites
mistaken conclusions about the <code>x</code> effect for the broader
population.</p>
<p>Second, this output is <em>inequitable</em>: it elevates one group
above all others. The reference group is often selected to be White for
<code>race</code>, Male for <code>sex</code>, etc., and thus induces a
bias in the presentation of results. Similarly, the <code>x:race</code>
effects are presented as deviations from the reference group
<code>x</code> effect: for example <code>x:raceB</code> refers to the
difference between the <code>x</code> effect for group <code>B</code>
and the <code>x</code> effect for the reference group <code>A</code>.
This implicitly treats one group as “normal” and the others as
“deviations from normal.”</p>
<p>Third, RGE is not well-designed to include interactions like
<code>x:race</code>. In addition to the difficulties with
interpretations and equitability, RGE is <em>statistically
inefficient</em> for the main effects. To see this, consider the
estimates and inference for the <code>x</code> effect under the
main-only model <code>y ~ x + race</code>:</p>
<table class="table">
<caption>Estimated x effect: lm(y ~ x + race)</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">Estimate</th>
<th align="right">Std. Error</th>
<th align="right">t value</th>
<th align="right">Pr(&gt;|t|)</th>
</tr></thead>
<tbody><tr class="odd">
<td align="left">x</td>
<td align="right">1.08</td>
<td align="right">0.04</td>
<td align="right">26.39</td>
<td align="right">0</td>
</tr></tbody>
</table>
<p>The estimates and standard errors of the <code>x</code> effect are
considerably different. This occurs because here, the <code>x</code>
effect refers to a global slope,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mn>1</mn></msub><mo>=</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>,</mo><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\alpha_1 = \mu(x+1, r) - \mu(x,r)</annotation></semantics></math>,
rather than a (reference) group-specific slope—even though the output
appears exactly the same. Usually, the standard errors will
<em>increase</em> when <code>x:race</code> is included, since the slope
is restricted to a subset of the data.</p>
<p>In aggregate, default <code>lm</code> output under RGE is at best
difficult to interpret and at worst outright misleading. It suffers from
alarming inequities and sacrifices statistical efficiency in the
presence of (<code>x:race</code>) interactions. These issues also occur
for the intercept parameters and compound for multiple categorical
variables and interactions.</p>
</div>
<div class="section level2">
<h2 id="abundance-based-constraints-abcs-the-solution">Abundance-Based Constraints (ABCs): the solution<a class="anchor" aria-label="anchor" href="#abundance-based-constraints-abcs-the-solution"></a>
</h2>
<p>Instead, suppose we call <code>lmabc</code> to fit the group-modified
model:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://drkowal.github.io/lmabc/">lmabc</a></span><span class="op">)</span></span>
<span><span class="va">fit_lmabc</span> <span class="op">=</span> <span class="fu"><a href="../reference/lmabc.html">lmabc</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span> <span class="op">+</span> <span class="va">race</span> <span class="op">+</span> <span class="va">x</span><span class="op">:</span><span class="va">race</span><span class="op">)</span></span></code></pre></div>
<p>The <code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code> output appears as follows:</p>
<table class="table">
<caption>ABC output: lmabc(y ~ x + race + x:race)</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">Estimate</th>
<th align="right">Std. Error</th>
<th align="right">t value</th>
<th align="right">Pr(&gt;|t|)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">2.85</td>
<td align="right">0.14</td>
<td align="right">20.71</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">x</td>
<td align="right">1.09</td>
<td align="right">0.04</td>
<td align="right">28.23</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">raceA</td>
<td align="right">1.58</td>
<td align="right">0.19</td>
<td align="right">8.28</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">raceB</td>
<td align="right">-1.10</td>
<td align="right">0.16</td>
<td align="right">-6.71</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">raceC</td>
<td align="right">-1.74</td>
<td align="right">0.55</td>
<td align="right">-3.18</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">raceD</td>
<td align="right">-0.29</td>
<td align="right">0.14</td>
<td align="right">-2.03</td>
<td align="right">0.04</td>
</tr>
<tr class="odd">
<td align="left">x:raceA</td>
<td align="right">0.42</td>
<td align="right">0.05</td>
<td align="right">7.74</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">x:raceB</td>
<td align="right">-0.44</td>
<td align="right">0.09</td>
<td align="right">-4.86</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">x:raceC</td>
<td align="right">-0.18</td>
<td align="right">0.09</td>
<td align="right">-1.94</td>
<td align="right">0.05</td>
</tr>
<tr class="even">
<td align="left">x:raceD</td>
<td align="right">-0.14</td>
<td align="right">0.05</td>
<td align="right">-2.70</td>
<td align="right">0.01</td>
</tr>
</tbody>
</table>
<p>First, every <code>race</code> group is represented: the results do
<em>not</em> elevate any single <code>race</code> group above the
others. This eliminates the presentation bias and provides more
<strong>equitable</strong> output.</p>
<p>Second, the <code>x</code> effect estimates and standard errors are
<em>nearly identical</em> to those in the main-only model
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>α</mi><mo accent="true">̂</mo></mover><mn>1</mn></msub><mo>=</mo></mrow><annotation encoding="application/x-tex">{\hat\alpha}_1 =</annotation></semantics></math>
1.08,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>α</mi><mo accent="true">̂</mo></mover><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo></mrow><annotation encoding="application/x-tex">SE({\hat\alpha}_1) =</annotation></semantics></math>
0.04). This illustrates two remarkable <strong>invariance properties of
ABCs</strong>:</p>
<ol style="list-style-type: decimal">
<li>The estimated <code>x</code> effects under <code>y ~ x + race</code>
and <code>y ~ x + race + x:race</code> are nearly identical; and<br>
</li>
<li>The standard errors of the <code>x</code> effects under
<code>y ~ x + race</code> and <code>y ~ x + race + x:race</code> are
<ol style="list-style-type: lower-alpha">
<li>Nearly identical when the <code>x:race</code> effect is small
or</li>
<li>Smaller for the group-modified model when the <code>x:race</code>
effect is large.</li>
</ol>
</li>
</ol>
<p>In effect, ABCs allow the inclusion of (<code>x:race</code>)
interactions “for free”: they have (almost) no impact on estimation and
inference for the main <code>x</code> effect. With ABCs, the analyst can
estimate group-specific <code>x</code> effects without worrying that the
addition of <code>x:race</code> will sacrifice power for the main
<code>x</code> effect (which occurs for RGE). And, when the interaction
effect <code>x:race</code> is substantial, the analyst gains <em>more
power</em> for the main <code>x</code> effect.</p>
<p>We emphasize several features of these invariance properties:</p>
<ul>
<li>They are unique to ABCs and do <em>not</em> occur for alternative
approaches (default RGE, sum-to-zero constraints, etc.);</li>
<li>They make no requirements about the true data-generating process;
and</li>
<li>They allow for dependencies between <code>x</code> and
<code>race</code> (as in this simulated dataset).</li>
</ul>
<p>The only condition is that, for continuous <code>x</code>, the scale
of <code>x</code> must be approximately the same within each
<code>race</code> group (no conditions are needed when <code>x</code> is
categorical; see below). This is reasonable: if a “one-unit change in
<code>x</code>” is not comparable for different <code>race</code>
groups, then only the group-modified model that includes
<code>race</code>-specific slopes is meaningful. In that case, there is
no reason to consider the <code>x</code> effect under the main-only
model. Empirically, these (near) invariance results are quite robust to
this condition.</p>
<p>Finally, these results improve <strong>interpretability</strong>: all
group-specific coefficients
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>γ</mi><mi>r</mi></msub><annotation encoding="application/x-tex">\gamma_r</annotation></semantics></math>
(e.g., <code>x:raceB</code>) now represent the difference between the
group-specific slope,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>,</mo><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mu(x+1, r) - \mu(x,r)</annotation></semantics></math>,
and the <em>properly global</em> <code>x</code> effect
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>α</mi><mn>1</mn></msub><annotation encoding="application/x-tex">\alpha_1</annotation></semantics></math>.
Similar interpretations apply to the intercept parameters.</p>
<div class="section level3">
<h3 id="abcs-some-details">ABCs: some details<a class="anchor" aria-label="anchor" href="#abcs-some-details"></a>
</h3>
<p>ABCs identify the group-specific parameters by constraining the
<em>group averages</em> to be zero,
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>γ</mi><mi>R</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munder><mo>∑</mo><mi>r</mi></munder><msub><mi>π</mi><mi>r</mi></msub><msub><mi>γ</mi><mi>r</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">
E_\pi(\gamma_R) = \sum_r \pi_r \gamma_r = 0
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>R</mi><annotation encoding="application/x-tex">R</annotation></semantics></math>
denotes a categorical random variable (e.g., <code>race</code>) with
probabilities
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>r</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>R</mi><mo>=</mo><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>π</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">Pr(R = r) = \pi_r</annotation></semantics></math>.
A similar constraint is then used for the group-specific intercept
parameters:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>β</mi><mi>R</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mo>∑</mo><mi>r</mi></msub><msub><mi>π</mi><mi>r</mi></msub><msub><mi>β</mi><mi>r</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">E_\pi(\beta_R) = \sum_r \pi_r \beta_r = 0</annotation></semantics></math>.
These linear constraints are constructed using
<code><a href="../reference/getConstraints.html">getConstraints()</a></code> and enforced during estimation, for
example using ordinary least squares <code><a href="../reference/lmabc.html">lmabc()</a></code>, maximum
likelihood <code><a href="../reference/glmabc.html">glmabc()</a></code>, and penalized least squares
<code><a href="../reference/cv.penlmabc.html">cv.penlmabc()</a></code>. Modifications are available for
categorical-categorical interactions.</p>
<p>The constraints above are general and include many special cases: RGE
uses
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mi>A</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\pi_A = 1</annotation></semantics></math>
(reference) and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mi>r</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\pi_r = 0</annotation></semantics></math>
otherwise, while sum-to-zero constraints use equal weights
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mi>r</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\pi_r = 1</annotation></semantics></math>
for all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>r</mi><annotation encoding="application/x-tex">r</annotation></semantics></math>.
However, <em>the choice of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><msub><mi>π</mi><mi>r</mi></msub><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{\pi_r\}</annotation></semantics></math>
is critical for equitability, statistical efficiency, and
interpretability.</em></p>
<p>ABCs use the empirically-observed proportions by group,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mi>r</mi></msub><mo>=</mo></mrow><annotation encoding="application/x-tex">\pi_r=</annotation></semantics></math><code>mean(race == r)</code>. As such, the parameters have a genuine
“group-average” interpretation. For instance, the global slope parameter
in the group-modified model is
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mn>1</mn></msub><mo>=</mo><msub><mi>E</mi><mi>π</mi></msub><mo stretchy="false" form="prefix">{</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>,</mo><mi>R</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>R</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="false" form="postfix">}</mo><mo>=</mo><munder><mo>∑</mo><mi>r</mi></munder><msub><mi>π</mi><mi>r</mi></msub><mo stretchy="false" form="prefix">{</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>,</mo><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">
\alpha_1 = E_{\pi}\{\mu(x+1, R) - \mu(x, R)\} = \sum_r \pi_r \{\mu(x+1, r) - \mu(x, r)\}
</annotation></semantics></math> i.e., the group average of the
group-specific <code>x</code> effects. Similar interpretations are
available for the global intercept:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mn>0</mn></msub><mo>=</mo><msub><mi>E</mi><mi>π</mi></msub><mo stretchy="false" form="prefix">{</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mi>R</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="false" form="postfix">}</mo><mo>=</mo><munder><mo>∑</mo><mi>r</mi></munder><msub><mi>π</mi><mi>r</mi></msub><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
\alpha_0 = E_{\pi}\{\mu(0, R)\} = \sum_r \pi_r \mu(0, r).
</annotation></semantics></math> Because ABCs identify properly global
(intercept and slope) parameters, the group-specific coefficients are
interpretable as the difference between the group-specific
<code>x</code> effect (or intercept) and the global/group-averaged
<code>x</code> effect (or intercept). There is no need to elevate any
single (reference) group.</p>
<p>ABCs may also use the population group proportions, if those are
known and passed to the function.</p>
</div>
<div class="section level3">
<h3 id="interpeting-the-lmabc-output">Interpeting the <code>lmabc</code> output<a class="anchor" aria-label="anchor" href="#interpeting-the-lmabc-output"></a>
</h3>
<p>Revisiting the output from <code>lmabc(y ~ x + race + x:race)</code>,
we summarize the main conclusions:</p>
<ul>
<li>The global <code>x</code> effect is significant and positive
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>α</mi><mo accent="true">̂</mo></mover><mn>1</mn></msub><mo>=</mo><mn>1.09</mn></mrow><annotation encoding="application/x-tex">{\hat\alpha}_1 = 1.09</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>α</mi><mo accent="true">̂</mo></mover><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0.04</mn></mrow><annotation encoding="application/x-tex">SE({\hat\alpha}_1) = 0.04</annotation></semantics></math>).</li>
<li>The <code>x:race</code> interaction effects show that the
group-specific <code>x</code> effect is significantly larger than
average for <code>race = A</code>
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>γ</mi><mo accent="true">̂</mo></mover><mi>A</mi></msub><mo>=</mo><mn>0.42</mn></mrow><annotation encoding="application/x-tex">{\hat\gamma}_A = 0.42</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>γ</mi><mo accent="true">̂</mo></mover><mi>A</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">SE({\hat\gamma}_A) = 0.05</annotation></semantics></math>),
significantly smaller than average for <code>race = B</code>
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>γ</mi><mo accent="true">̂</mo></mover><mi>B</mi></msub><mo>=</mo><mo>−</mo><mn>0.44</mn></mrow><annotation encoding="application/x-tex">{\hat\gamma}_B = -0.44</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>γ</mi><mo accent="true">̂</mo></mover><mi>B</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0.09</mn></mrow><annotation encoding="application/x-tex">SE({\hat\gamma}_B) = 0.09</annotation></semantics></math>)
and <code>race = D</code>
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>γ</mi><mo accent="true">̂</mo></mover><mi>D</mi></msub><mo>=</mo><mo>−</mo><mn>0.14</mn></mrow><annotation encoding="application/x-tex">{\hat\gamma}_D = -0.14</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>γ</mi><mo accent="true">̂</mo></mover><mi>D</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">SE({\hat\gamma}_D) = 0.05</annotation></semantics></math>),
and somewhat smaller than average for <code>race = C</code>
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>γ</mi><mo accent="true">̂</mo></mover><mi>C</mi></msub><mo>=</mo><mo>−</mo><mn>0.18</mn></mrow><annotation encoding="application/x-tex">{\hat\gamma}_C = -0.18</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>γ</mi><mo accent="true">̂</mo></mover><mi>C</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0.09</mn></mrow><annotation encoding="application/x-tex">SE({\hat\gamma}_C) = 0.09</annotation></semantics></math>).</li>
<li>The group-specific slopes are computed by summing the relevant
coefficients, for example
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>,</mo><mi>A</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>A</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>α</mi><mn>1</mn></msub><mo>+</mo><msub><mi>γ</mi><mi>A</mi></msub><mo>=</mo><mn>1.51</mn></mrow><annotation encoding="application/x-tex">\mu(x+1, A) - \mu(x,A) = \alpha_1 + \gamma_A = 1.51</annotation></semantics></math>
is the group-specific <code>x</code> effect for
<code>race = A</code>.</li>
<li>Similar interpretations apply for the intercept coefficients.</li>
</ul>
</div>
</div>
<div class="section level2">
<h2 id="categorical-categorical-interactions">Categorical-categorical interactions<a class="anchor" aria-label="anchor" href="#categorical-categorical-interactions"></a>
</h2>
<p>The case of categorical-categorical interactions is arguably even
more cumbersome for default (RGE) methods—and yet ABCs offer an even
cleaner solution. Consider the <code>lm</code> output for two models
that feature the categorical covariates <code>race</code> and
<code>sex</code>: the main-only model <code>y ~ race + sex</code> and
the group-modified model, <code>y ~ race + sex + race:sex</code>.</p>
<table class="table kable_wrapper"><tbody><tr>
<td>
<table class="table">
<caption>Default output: lm(y ~ race + sex)</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">Estimate</th>
<th align="right">Std. Error</th>
<th align="right">t value</th>
<th align="right">Pr(&gt;|t|)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">9.58</td>
<td align="right">0.12</td>
<td align="right">81.70</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">raceB</td>
<td align="right">-7.69</td>
<td align="right">0.21</td>
<td align="right">-37.32</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">raceC</td>
<td align="right">-14.38</td>
<td align="right">0.22</td>
<td align="right">-66.12</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">raceD</td>
<td align="right">-7.50</td>
<td align="right">0.19</td>
<td align="right">-39.23</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">sexvv</td>
<td align="right">-0.02</td>
<td align="right">0.16</td>
<td align="right">-0.09</td>
<td align="right">0.93</td>
</tr>
</tbody>
</table>
</td>
<td>
<table class="table">
<caption>Default output: lm(y ~ race + sex + race:sex)</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">Estimate</th>
<th align="right">Std. Error</th>
<th align="right">t value</th>
<th align="right">Pr(&gt;|t|)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">9.59</td>
<td align="right">0.12</td>
<td align="right">76.84</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">raceB</td>
<td align="right">-7.71</td>
<td align="right">0.23</td>
<td align="right">-33.89</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">raceC</td>
<td align="right">-14.63</td>
<td align="right">0.31</td>
<td align="right">-47.72</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">raceD</td>
<td align="right">-7.40</td>
<td align="right">0.27</td>
<td align="right">-27.22</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">sexvv</td>
<td align="right">-0.11</td>
<td align="right">0.31</td>
<td align="right">-0.35</td>
<td align="right">0.72</td>
</tr>
<tr class="even">
<td align="left">raceB:sexvv</td>
<td align="right">0.08</td>
<td align="right">0.54</td>
<td align="right">0.15</td>
<td align="right">0.88</td>
</tr>
<tr class="odd">
<td align="left">raceC:sexvv</td>
<td align="right">0.46</td>
<td align="right">0.47</td>
<td align="right">0.98</td>
<td align="right">0.33</td>
</tr>
<tr class="even">
<td align="left">raceD:sexvv</td>
<td align="right">-0.05</td>
<td align="right">0.42</td>
<td align="right">-0.13</td>
<td align="right">0.90</td>
</tr>
</tbody>
</table>
</td>
</tr></tbody></table>
<p>In both cases, the reference groups for <code>race</code> (here,
<code>A</code>) and <code>sex</code> (here, <code>uu</code>) are absent
from all main and interaction effects. The output again is misleading:
even for the simpler model <code>y ~ race + sex</code>, the main effects
require consideration of <em>both</em> reference groups. For example,
the intercept estimates
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mn>0</mn></msub><mo>=</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>r</mi><mi>a</mi><mi>c</mi><mi>e</mi><mo>=</mo><mi>A</mi><mo>,</mo><mi>s</mi><mi>e</mi><mi>x</mi><mo>=</mo><mi>u</mi><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\alpha_0 = \mu(race = A, sex = uu)</annotation></semantics></math>,
i.e., the expected response for <code>race = A</code> and
<code>sex = uu</code>. Similarly, the main effects such as
<code>sexvv</code> estimate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>r</mi><mi>a</mi><mi>c</mi><mi>e</mi><mo>=</mo><mi>A</mi><mo>,</mo><mi>s</mi><mi>e</mi><mi>x</mi><mo>=</mo><mi>v</mi><mi>v</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>r</mi><mi>a</mi><mi>c</mi><mi>e</mi><mo>=</mo><mi>A</mi><mo>,</mo><mi>s</mi><mi>e</mi><mi>x</mi><mo>=</mo><mi>u</mi><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mu(race = A, sex = vv) - \mu(race = A, sex = uu)</annotation></semantics></math>,
i.e., the difference in the expected responses between
<code>sex = vv</code> and <code>sex = uu</code> but <em>only for
<code>race = A</code></em>. When the reference groups are set at the
usual values (White for <code>race</code> and Male for
<code>sex</code>), these parametrizations are clearly inequitable.
Finally, we see that the standard errors for the main effects increase
when the <code>race:sex</code> interaction is added to to the model.</p>
<p>ABCs completely circumvent these issues. Consider the same two
models, but now subject to ABCs:</p>
<table class="table kable_wrapper"><tbody><tr>
<td>
<table class="table">
<caption>ABC output: lmabc(y ~ race + sex)</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">Estimate</th>
<th align="right">Std. Error</th>
<th align="right">t value</th>
<th align="right">Pr(&gt;|t|)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">3.54</td>
<td align="right">0.07</td>
<td align="right">52.49</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">raceA</td>
<td align="right">6.03</td>
<td align="right">0.10</td>
<td align="right">58.32</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">raceB</td>
<td align="right">-1.66</td>
<td align="right">0.16</td>
<td align="right">-10.13</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">raceC</td>
<td align="right">-8.35</td>
<td align="right">0.16</td>
<td align="right">-53.33</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">raceD</td>
<td align="right">-1.46</td>
<td align="right">0.11</td>
<td align="right">-13.49</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">sexuu</td>
<td align="right">0.01</td>
<td align="right">0.07</td>
<td align="right">0.09</td>
<td align="right">0.93</td>
</tr>
<tr class="odd">
<td align="left">sexvv</td>
<td align="right">-0.01</td>
<td align="right">0.09</td>
<td align="right">-0.09</td>
<td align="right">0.93</td>
</tr>
</tbody>
</table>
</td>
<td>
<table class="table">
<caption>ABC output: lmabc(y ~ race + sex + race:sex)</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">Estimate</th>
<th align="right">Std. Error</th>
<th align="right">t value</th>
<th align="right">Pr(&gt;|t|)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">3.54</td>
<td align="right">0.07</td>
<td align="right">52.41</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">raceA</td>
<td align="right">6.03</td>
<td align="right">0.10</td>
<td align="right">58.23</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">raceB</td>
<td align="right">-1.66</td>
<td align="right">0.16</td>
<td align="right">-10.11</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">raceC</td>
<td align="right">-8.35</td>
<td align="right">0.16</td>
<td align="right">-53.25</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">raceD</td>
<td align="right">-1.46</td>
<td align="right">0.11</td>
<td align="right">-13.47</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">sexuu</td>
<td align="right">0.01</td>
<td align="right">0.07</td>
<td align="right">0.09</td>
<td align="right">0.93</td>
</tr>
<tr class="odd">
<td align="left">sexvv</td>
<td align="right">-0.01</td>
<td align="right">0.09</td>
<td align="right">-0.09</td>
<td align="right">0.93</td>
</tr>
<tr class="even">
<td align="left">raceA:sexuu</td>
<td align="right">0.02</td>
<td align="right">0.04</td>
<td align="right">0.36</td>
<td align="right">0.72</td>
</tr>
<tr class="odd">
<td align="left">raceB:sexuu</td>
<td align="right">0.00</td>
<td align="right">0.08</td>
<td align="right">0.04</td>
<td align="right">0.97</td>
</tr>
<tr class="even">
<td align="left">raceC:sexuu</td>
<td align="right">-0.23</td>
<td align="right">0.20</td>
<td align="right">-1.19</td>
<td align="right">0.24</td>
</tr>
<tr class="odd">
<td align="left">raceD:sexuu</td>
<td align="right">0.11</td>
<td align="right">0.17</td>
<td align="right">0.67</td>
<td align="right">0.50</td>
</tr>
<tr class="even">
<td align="left">raceA:sexvv</td>
<td align="right">-0.08</td>
<td align="right">0.22</td>
<td align="right">-0.36</td>
<td align="right">0.72</td>
</tr>
<tr class="odd">
<td align="left">raceB:sexvv</td>
<td align="right">-0.01</td>
<td align="right">0.34</td>
<td align="right">-0.04</td>
<td align="right">0.97</td>
</tr>
<tr class="even">
<td align="left">raceC:sexvv</td>
<td align="right">0.13</td>
<td align="right">0.11</td>
<td align="right">1.19</td>
<td align="right">0.24</td>
</tr>
<tr class="odd">
<td align="left">raceD:sexvv</td>
<td align="right">-0.03</td>
<td align="right">0.05</td>
<td align="right">-0.67</td>
<td align="right">0.50</td>
</tr>
</tbody>
</table>
</td>
</tr></tbody></table>
<p>First, each group is present in both the main effects and
interactions. There is no need to consider reference groups, and thus no
single (<code>race</code> or <code>sex</code>) group is elevated above
the others.</p>
<p>Second, <em>all</em> main effect estimates—including the
<code>(Intercept)</code>, all <code>race</code> effects, and both
<code>sex</code> effects—are <em>identical</em> between the models that
do and do not include the <code>race:sex</code> interaction. Unlike the
previous setting with continuous-categorical interactions
(<code>x:race</code>), this estimation invariance is <em>exact</em>.
Importantly, this result makes no requirements on the true
data-generating process or the categorical covariates, which here are
highly dependent.</p>
<p>Similarly, the main effect standard errors—again for the
<code>(Intercept)</code>, all <code>race</code> effects, and both
<code>sex</code> effects—are (almost) identical between the two
models.</p>
<p>We summarize these (provable) <strong>invariance properties of
ABCs</strong> for categorical-categorical interactions:</p>
<ol style="list-style-type: decimal">
<li>The estimated <code>(Intercept)</code>, <code>race</code>, and
<code>sex</code> effects under <code>y ~ race + sex</code> and
<code>y ~ race + sex + race:sex</code> are identical; and<br>
</li>
<li>The standard errors of <code>(Intercept)</code>, <code>race</code>,
and <code>sex</code> under <code>y ~ race + sex</code> and
<code>y ~ race + sex + race:sex</code> are
<ol style="list-style-type: lower-alpha">
<li>Nearly identical when the <code>race:sex</code> effect is small
or</li>
<li>Smaller for the group-modified model when the <code>race:sex</code>
effect is large.</li>
</ol>
</li>
</ol>
<p>Again, the analyst may include (<code>race:sex</code>) interaction
effects “for free”: the main effect estimates are unchanged, and the
statistical power for the main effects can only increase. Thus, we
require that all main effects are included for any
categorical-categorical or categorical-continuous interactions.</p>
</div>
<div class="section level2">
<h2 id="interpreting-abcs-with-care">Interpreting ABCs with care<a class="anchor" aria-label="anchor" href="#interpreting-abcs-with-care"></a>
</h2>
<p>By design, ABCs leverage the (sample or population) categorical
proportions to provide 1) more equitable output, 2) greater statistical
efficiency, and 3) more interpretable parameters and estimates with
properly global (i.e., group-averaged) main effects. However, the
<em>group-specific</em> coefficients must be interpreted carefully in
the context of the abundances
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><msub><mi>π</mi><mi>r</mi></msub><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{\pi_r\}</annotation></semantics></math>.</p>
<p>For instance, consider the simple model <code>y ~ sex</code>,</p>
<table class="table">
<caption>ABC output: lmabc(y ~ sex)</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">Estimate</th>
<th align="right">Std. Error</th>
<th align="right">t value</th>
<th align="right">Pr(&gt;|t|)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">3.54</td>
<td align="right">0.22</td>
<td align="right">16.22</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">sexuu</td>
<td align="right">1.73</td>
<td align="right">0.20</td>
<td align="right">8.84</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">sexvv</td>
<td align="right">-2.15</td>
<td align="right">0.24</td>
<td align="right">-8.84</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>With two groups, ABCs imply that one effect must be positive and the
other must be negative, as the two must average to zero. These effects
are partly determined by the group abundances,
<code>mean(sex=="uu")</code> = 0.55 and <code>mean(sex=="vv")</code> =
0.45. Because <code>vv</code> has a <em>lower</em> proportion, its
estimated coefficient must be <em>higher</em> (in absolute value) to
satisfy ABCs. Thus, we cannot merely interpret the <code>vv</code>
effect as “larger than” the <code>uu</code> effect.</p>
<p>Fortunately, the standard errors inflate proportionally: hence, the
<code>t value</code> statistics (<code>Estimate / Std. Error</code>) are
equal and opposite. Similarly, the p-values will be identical for these
(<code>sexuu</code> and <code>sexvv</code>) main effects.</p>
<p>Even with these caveats, ABCs offer an appealing parametrization of
this ANOVA model. First, the estimated intercept <em>exactly</em> equals
the sample mean, <code>mean(y)</code> = 3.54. Second, the
<code>sex</code>-specific coefficients <em>exactly</em> equal the
difference between the group-specific means and the overall mean,
<code>mean(y[sex=="uu"]) - mean(y)</code> = 1.73. This is certainly a
natural way to parametrize the group-specific and global effects for
this model.</p>
</div>
<div class="section level2">
<h2 id="additional-details-about-lmabc">Additional details about <code>lmabc</code><a class="anchor" aria-label="anchor" href="#additional-details-about-lmabc"></a>
</h2>
<p>The <code>lmabc</code> package includes implementations for many
common methods: <code>summary</code>, <code>coef</code>,
<code>print</code>, <code>plot</code>, <code>predict</code>,
<code>logLik</code>, <code>vcov</code>, and more.</p>
<p><code>lmabc</code> also includes methods for generalized linear
models (GLMs) with categorical covariates (<code>glmabc</code>) and
penalized (lasso and ridge) regression with cross-validation
(<code>cv.penlmabc</code>). These methods, like <code>lmabc</code>, can
handle multiple continuous and categorical covariates and their
interactions. We note a few points:</p>
<ul>
<li>The invariance properties of ABCs remain valid for multiple
continuous and categorical covariates and their interactions. The
conditions change slightly (see the reference below) but approximate
invariance applies quite generally.</li>
<li>For GLMs (<code>glmabc</code>), ABCs offer equitability and
interpretability, but estimation invariance applies only for OLS. This
work is currently under development.</li>
<li>For penalized (ridge or lasso) regression, ABCs are immensely
valuable. Because these penalized estimators “shrink” the coefficients
toward zero, default RGE estimates of group-specific effects are
<em>statistically biased toward the reference group</em>. This is
especially concerning for protected groups (race, sex, religion, etc.)
but also implies that 1) estimates and predictions depend on the choice
of reference group and 2) differences between group-specific
<code>x</code> effects and reference group <code>x</code> effects are
attenuated and obscured. ABCs resolve these critical limitations, again
by providing efficient estimation and shrinkage toward <em>properly
global</em> coefficients. The statistical properties of these estimators
are currently under development.</li>
</ul>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<p>Kowal, D. (2024). Facilitating heterogeneous effect estimation via
statistically efficient categorical modifiers. <a href="https://arxiv.org/abs/2408.00618" class="external-link uri">https://arxiv.org/abs/2408.00618</a></p>
<p>Kowal, D. (2024). Regression with race-modifiers: towards equity and
interpretability. <a href="https://doi.org/10.1101/2024.01.04.23300033" class="external-link uri">https://doi.org/10.1101/2024.01.04.23300033</a></p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Dan Kowal, Prayag Gordy, Virginia Baskin, Jai Uparkar.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
